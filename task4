import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
data = pd.read_csv(r'C:\Users\admin\Downloads\archive (11)\creditcard.csv')


# Step 2: Display basic information and describe the data
print(data.info())
print(data.describe())

# Step 3: Preprocess the Data
# Check for missing values
if data.isnull().sum().any():
    print("Missing values found, filling with mean...")
    data.fillna(data.mean(), inplace=True)

# Normalize the features (excluding the target variable 'Class')
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data.drop('Class', axis=1))

# Step 4: Handle Class Imbalance using SMOTE or Undersampling
X = data.drop('Class', axis=1)
y = data['Class']

# Option 1: Use SMOTE for oversampling
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)


# Step 5: Train-Test Split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Step 6: Train the Model (Random Forest or Logistic Regression)

# Train using Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Alternatively, train using Logistic Regression
# log_reg_model = LogisticRegression()
# log_reg_model.fit(X_train, y_train)

# Step 7: Model Prediction
y_pred_rf = rf_model.predict(X_test)

# Alternatively, for Logistic Regression
# y_pred_log_reg = log_reg_model.predict(X_test)

# Step 8: Evaluate the Model using Precision, Recall, F1-Score

# Random Forest evaluation
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# Alternatively, for Logistic Regression evaluation:
# print("Logistic Regression Classification Report:")
# print(classification_report(y_test, y_pred_log_reg))

# Step 9: Confusion Matrix Visualization
cm_rf = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['Genuine', 'Fraudulent'], yticklabels=['Genuine', 'Fraudulent'])
plt.title('Random Forest Confusion Matrix')
plt.show()

# Alternatively, for Logistic Regression confusion matrix:
# cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)
# sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', xticklabels=['Genuine', 'Fraudulent'], yticklabels=['Genuine', 'Fraudulent'])
# plt.title('Logistic Regression Confusion Matrix')
# plt.show()
